{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Question 4\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"glass.csv\")\n",
        "\n",
        "# Extract the features (X) and the target variable (Y)\n",
        "X = data.iloc[:, 1:-1]\n",
        "Y = data.iloc[:, -1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def euclidean_distance(point1, point2):\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Define the number of neighbors (k) for the KNN model\n",
        "k = 5\n",
        "\n",
        "# Create an instance of the KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=k, metric=euclidean_distance)\n",
        "\n",
        "# Fit the model on the training data\n",
        "knn.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "Y_pred = knn.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "k_values = [1, 3, 5, 7, 9]  # Different values of k\n",
        "\n",
        "for k in k_values:\n",
        "    # Create an instance of the KNN classifier with the current k value\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, metric=euclidean_distance)\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    knn.fit(X_train, Y_train)\n",
        "    \n",
        "    # Make predictions on the testing data\n",
        "    Y_pred = knn.predict(X_test)\n",
        "    \n",
        "    # Calculate the accuracy of the predictions\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    print(\"Accuracy for k =\", k, \":\", accuracy)\n",
        "\n",
        "# Create an instance of the KNN classifier from sklearn\n",
        "sklearn_knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit the sklearn model on the training data\n",
        "sklearn_knn.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions using the sklearn model\n",
        "sklearn_Y_pred = sklearn_knn.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the predictions from the sklearn model\n",
        "sklearn_accuracy = accuracy_score(Y_test, sklearn_Y_pred)\n",
        "\n",
        "print(\"Accuracy using sklearn's KNN model:\", sklearn_accuracy)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "max_depth_values = range(5, 11)  # Range of maximum depths to try\n",
        "\n",
        "for max_depth in max_depth_values:\n",
        "    # Create an instance of the DecisionTreeClassifier with the current maximum depth\n",
        "    dt_classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
        "    \n",
        "    # Fit the model on the training data\n",
        "    dt_classifier.fit(X_train, Y_train)\n",
        "    \n",
        "    # Make predictions on the testing data\n",
        "    Y_pred = dt_classifier.predict(X_test)\n",
        "    \n",
        "    # Calculate the accuracy of the predictions\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    print(\"Accuracy for max_depth =\", max_depth, \":\", accuracy)\n",
        "\n",
        "# Select a specific maximum depth for visualization\n",
        "selected_max_depth = 5\n",
        "\n",
        "# Create an instance of the DecisionTreeClassifier with the selected maximum depth\n",
        "dt_classifier = DecisionTreeClassifier(max_depth=selected_max_depth)\n",
        "\n",
        "# Fit the model on the training data\n",
        "dt_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# Plot the decision tree\n",
        "plt.figure(figsize=(12, 8))\n",
        "tree.plot_tree(dt_classifier, feature_names=X.columns, class_names=dt_classifier.classes_, filled=True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-QawFznyqQRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 1\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate, epochs, penalty=None, alpha=0):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.penalty = penalty\n",
        "        self.alpha = alpha\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        \n",
        "        # Initialize weights and bias to zeros\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        \n",
        "        for _ in range(self.epochs):\n",
        "            # Compute predictions\n",
        "            y_pred = self.predict(X)\n",
        "            \n",
        "            # Compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "            \n",
        "            # Regularization\n",
        "            if self.penalty is None:\n",
        "                dw += 0\n",
        "            elif self.penalty == \"L1\":\n",
        "                dw += (self.alpha / n_samples) * np.sign(self.weights)\n",
        "            elif self.penalty == \"L2\":\n",
        "                dw += (2 * self.alpha / n_samples) * self.weights\n",
        "            \n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "# Example\n",
        "X_train = np.array([[1, 1], [2, 2], [3, 3]])\n",
        "y_train = np.array([2, 3, 4])\n",
        "\n",
        "regression = LinearRegression(learning_rate=0.01, epochs=100, penalty=\"L2\", alpha=0.1)\n",
        "regression.fit(X_train, y_train)\n",
        "\n",
        "X_test = np.array([[4, 4], [5, 5]])\n",
        "predictions = regression.predict(X_test)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "FeSLpKeN-B_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 2\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "data = pd.read_csv('real_estate.csv')\n",
        "print(data.isnull().sum())\n",
        "# Get the column names\n",
        "columns = data.columns[1:-1]  # Exclude the first and last column\n",
        "\n",
        "# Plot the columns against the last column\n",
        "for column in columns:\n",
        "    plt.scatter(data[column], data['price'])\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Price')\n",
        "    plt.show()\n",
        "data = data.drop(['No'], axis=1)\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Custom Linear Regression\n",
        "lr = LinearRegression(learning_rate=0.01, epochs=100)\n",
        "lr.fit(X_train, y_train)\n",
        "lr_y_pred = lr.predict(X_test)\n",
        "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
        "lr_r2 = r2_score(y_test, lr_y_pred)\n",
        "print(\"Custom Linear Regression:\")\n",
        "print(\"MSE:\", lr_mse)\n",
        "print(\"R2:\", lr_r2)\n",
        "\n",
        "# Custom Lasso Regression\n",
        "lasso = LinearRegression(learning_rate=0.01, epochs=100, penalty=\"L1\", alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "lasso_y_pred = lasso.predict(X_test)\n",
        "lasso_mse = mean_squared_error(y_test, lasso_y_pred)\n",
        "lasso_r2 = r2_score(y_test, lasso_y_pred)\n",
        "print(\"Custom Lasso Regression:\")\n",
        "print(\"MSE:\", lasso_mse)\n",
        "print(\"R2:\", lasso_r2)\n",
        "\n",
        "# Custom Ridge Regression\n",
        "ridge = LinearRegression(learning_rate=0.01, epochs=100, penalty=\"L2\", alpha=0.1)\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_y_pred = ridge.predict(X_test)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_y_pred)\n",
        "ridge_r2 = r2_score(y_test, ridge_y_pred)\n",
        "print(\"Custom Ridge Regression:\")\n",
        "print(\"MSE:\", ridge_mse)\n",
        "print(\"R2:\", ridge_r2)\n",
        "# Sklearn Linear Regression\n",
        "sklearn_lr = LinearRegression()\n",
        "sklearn_lr.fit(X_train, y_train)\n",
        "sklearn_lr_y_pred = sklearn_lr.predict(X_test)\n",
        "sklearn_lr_mse = mean_squared_error(y_test, sklearn_lr_y_pred)\n",
        "sklearn_lr_r2 = r2_score(y_test, sklearn_lr_y_pred)\n",
        "print(\"Sklearn Linear Regression:\")\n",
        "print(\"MSE:\", sklearn_lr_mse)\n",
        "print(\"R2:\", sklearn_lr_r2)\n",
        "\n",
        "# Sklearn Lasso Regression\n",
        "sklearn_lasso = Lasso(alpha=0.1)\n",
        "sklearn_lasso.fit(X_train, y_train)\n",
        "sklearn_lasso_y_pred = sklearn_lasso.predict(X_test)\n",
        "sklearn_lasso_mse = mean_squared_error(y_test, sklearn_lasso_y_pred)\n",
        "sklearn_lasso_r2 = r2_score(y_test, sklearn_lasso_y_pred)\n",
        "print(\"Sklearn Lasso Regression:\")\n",
        "print(\"MSE:\", sklearn_lasso_mse)\n",
        "print(\"R2:\", sklearn_lasso_r2)\n",
        "\n",
        "# Sklearn Ridge Regression\n",
        "sklearn_ridge = Ridge(alpha=0.1)\n",
        "sklearn_ridge.fit(X_train, y_train)\n",
        "sklearn_ridge_y_pred = sklearn_ridge.predict(X_test)\n",
        "sklearn_ridge_mse = mean_squared_error(y_test, sklearn_ridge_y_pred)\n",
        "sklearn_ridge_r2 = r2_score(y_test, sklearn_ridge_y_pred)\n",
        "print(\"Sklearn Ridge Regression:\")\n",
        "print(\"MSE:\", sklearn_ridge_mse)\n",
        "print(\"R2:\", sklearn_ridge_r2)\n"
      ],
      "metadata": {
        "id": "wH74EJ9oAiD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 3\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Separate the features (X) and target (y)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Create a train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Sigmoid function implementation.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array.\n",
        "    \n",
        "    Returns:\n",
        "    s -- Sigmoid function applied to x.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the logistic regression model to the training data.\n",
        "        \n",
        "        Arguments:\n",
        "        X -- Training data, shape (m, n_features).\n",
        "        y -- Target labels, shape (m,).\n",
        "        \"\"\"\n",
        "        m, n_features = X.shape\n",
        "        \n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        \n",
        "        # Gradient descent\n",
        "        for _ in range(self.num_iterations):\n",
        "            # Linear combination of weights and features\n",
        "            linear_combination = np.dot(X, self.weights) + self.bias\n",
        "            \n",
        "            # Apply sigmoid activation function\n",
        "            y_pred = sigmoid(linear_combination)\n",
        "            \n",
        "            # Gradient calculations\n",
        "            dw = (1 / m) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / m) * np.sum(y_pred - y)\n",
        "            \n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the target labels for new data.\n",
        "        \n",
        "        Arguments:\n",
        "        X -- Data to predict, shape (m, n_features).\n",
        "        \n",
        "        Returns:\n",
        "        y_pred -- Predicted labels, shape (m,).\n",
        "        \"\"\"\n",
        "        linear_combination = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = sigmoid(linear_combination)\n",
        "        y_pred = np.round(y_pred).astype(int)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Separate the features (X) and target (y)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Create a train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom Logistic Regression\n",
        "class LogisticRegressionCustom:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Implementation of fit method (same as before)\n",
        "        ...\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # Implementation of predict method (same as before)\n",
        "        ...\n",
        "\n",
        "# Fit and predict using the custom logistic regression model\n",
        "custom_model = LogisticRegressionCustom()\n",
        "custom_model.fit(X_train, y_train)\n",
        "custom_predictions = custom_model.predict(X_test)\n",
        "\n",
        "# Fit and predict using scikit-learn's logistic regression model with different penalties\n",
        "penalties = ['l1', 'l2', 'elasticnet', 'none']\n",
        "for penalty in penalties:\n",
        "    sklearn_model = LogisticRegression(penalty=penalty)\n",
        "    sklearn_model.fit(X_train, y_train)\n",
        "    sklearn_predictions = sklearn_model.predict(X_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_test, sklearn_predictions)\n",
        "    print(f\"Accuracy score using scikit-learn logistic regression (penalty: {penalty}): {accuracy:.4f}\")\n",
        "\n",
        "custom_accuracy = accuracy_score(y_test, custom_predictions)\n",
        "print(f\"Accuracy score using custom logistic regression: {custom_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Separate the features (X) and target (y)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Create a train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Custom Logistic Regression\n",
        "class LogisticRegressionCustom:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Implementation of fit method (same as before)\n",
        "        ...\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # Implementation of predict method (same as before)\n",
        "        ...\n",
        "\n",
        "# Fit and predict using the custom logistic regression model\n",
        "custom_model = LogisticRegressionCustom()\n",
        "custom_model.fit(X_train, y_train)\n",
        "custom_predictions = custom_model.predict(X_test)\n",
        "\n",
        "# Fit and predict using scikit-learn's logistic regression model with different penalties\n",
        "penalties = ['l1', 'l2', 'elasticnet', 'none']\n",
        "best_sklearn_model = None\n",
        "best_sklearn_accuracy = 0\n",
        "\n",
        "for penalty in penalties:\n",
        "    sklearn_model = LogisticRegression(penalty=penalty)\n",
        "    sklearn_model.fit(X_train, y_train)\n",
        "    sklearn_predictions = sklearn_model.predict(X_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_test, sklearn_predictions)\n",
        "    if accuracy > best_sklearn_accuracy:\n",
        "        best_sklearn_accuracy = accuracy\n",
        "        best_sklearn_model = sklearn_model\n",
        "    \n",
        "    print(f\"Accuracy score using scikit-learn logistic regression (penalty: {penalty}): {accuracy:.4f}\")\n",
        "    print(f\"Classification report using scikit-learn logistic regression (penalty: {penalty}):\\n\"\n",
        "          f\"{classification_report(y_test, sklearn_predictions)}\")\n",
        "    print(f\"Confusion matrix using scikit-learn logistic regression (penalty: {penalty}):\\n\"\n",
        "          f\"{confusion_matrix(y_test, sklearn_predictions)}\\n\")\n",
        "\n",
        "custom_accuracy = accuracy_score(y_test, custom_predictions)\n",
        "print(f\"Accuracy score using custom logistic regression: {custom_accuracy:.4f}\")\n",
        "print(\"Classification report using custom logistic regression:\\n\"\n",
        "      f\"{classification_report(y_test, custom_predictions)}\")\n",
        "print(\"Confusion matrix using custom logistic regression:\\n\"\n",
        "      f\"{confusion_matrix(y_test, custom_predictions)}\\n\")\n",
        "\n",
        "print(\"Best model using scikit-learn logistic regression:\")\n",
        "print(f\"Accuracy score: {best_sklearn_accuracy:.4f}\")\n",
        "print(f\"Classification report:\\n{classification_report(y_test, best_sklearn_model.predict(X_test))}\")\n",
        "print(f\"Confusion matrix:\\n{confusion_matrix(y_test, best_sklearn_model.predict(X_test))}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IupWVHOrA0Dm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}