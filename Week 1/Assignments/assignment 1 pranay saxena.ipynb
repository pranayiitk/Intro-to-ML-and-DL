{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "# Using Google Colab with GitHub\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKJ4bd5rt1wy"
      },
      "source": [
        "\n",
        "[Google Colaboratory](http://colab.research.google.com) is designed to integrate cleanly with GitHub, allowing both loading notebooks from github and saving notebooks to github."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Number of features\n",
        "n_features = 5\n",
        "\n",
        "# Generate random feature data\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "\n",
        "# Generate random target data\n",
        "true_coefficients = np.random.randn(n_features)\n",
        "true_intercept = np.random.randn()\n",
        "y = np.dot(X, true_coefficients) + true_intercept\n",
        "\n",
        "# Visualize the data\n",
        "fig, axs = plt.subplots(n_features, 1, figsize=(8, 6))\n",
        "\n",
        "for i in range(n_features):\n",
        "    # Plot the target against each feature\n",
        "    axs[i].scatter(X[:, i], y, alpha=0.5, label='Data')\n",
        "\n",
        "    # Compute the best-fit line using numpy's polyfit function\n",
        "    coefficients = np.polyfit(X[:, i], y, deg=1)\n",
        "    best_fit_line = np.polyval(coefficients, X[:, i])\n",
        "\n",
        "    # Plot the best-fit line\n",
        "    axs[i].plot(X[:, i], best_fit_line, color='red', label='Best Fit Line')\n",
        "\n",
        "    axs[i].set_xlabel(f'Feature {i+1}')\n",
        "    axs[i].set_ylabel('Target')\n",
        "    axs[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3_JEB3GvIh_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Number of features\n",
        "n_features = 2\n",
        "\n",
        "# Number of classes\n",
        "n_classes = 2\n",
        "\n",
        "# Number of clusters per class\n",
        "n_clusters_per_class = 2\n",
        "\n",
        "# Generate classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=n_samples,\n",
        "    n_features=n_features,\n",
        "    n_informative=n_features,\n",
        "    n_redundant=0,\n",
        "    n_classes=n_classes,\n",
        "    n_clusters_per_class=n_clusters_per_class\n",
        ")\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for class_value in np.unique(y):\n",
        "    # Select data points of the current class\n",
        "    X_class = X[y == class_value]\n",
        "\n",
        "    # Plot the data points\n",
        "    plt.scatter(X_class[:, 0], X_class[:, 1], label=f'Class {class_value}')\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.title('Classification Dataset')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MiFCf6OQIoHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Number of features\n",
        "n_features = 2\n",
        "\n",
        "# Number of clusters\n",
        "n_clusters = 4\n",
        "\n",
        "# Generate clustering dataset\n",
        "X, y = make_blobs(\n",
        "    n_samples=n_samples,\n",
        "    n_features=n_features,\n",
        "    centers=n_clusters,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Clustering Dataset')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8IM2SZhiIruO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Number of features\n",
        "n_features = 2\n",
        "\n",
        "# Number of classes\n",
        "n_classes = 2\n",
        "\n",
        "# Number of clusters per class\n",
        "n_clusters_per_class = 1\n",
        "\n",
        "# Imbalance ratio (5% minority class)\n",
        "imbalance_ratio = 0.05\n",
        "\n",
        "# Generate imbalanced classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=n_samples,\n",
        "    n_features=n_features,\n",
        "    n_informative=n_features,\n",
        "    n_redundant=0,\n",
        "    n_classes=n_classes,\n",
        "    weights=[imbalance_ratio, 1 - imbalance_ratio],\n",
        "    n_clusters_per_class=n_clusters_per_class,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Count the class distribution before oversampling\n",
        "class_distribution_before = Counter(y)\n",
        "print(\"Class distribution before oversampling:\", class_distribution_before)\n",
        "\n",
        "# Plot the data before oversampling\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Data before oversampling')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Oversample the minority class using SMOTE\n",
        "oversampler = SMOTE()\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "# Count the class distribution after oversampling\n",
        "class_distribution_after = Counter(y_resampled)\n",
        "print(\"Class distribution after oversampling:\", class_distribution_after)\n",
        "\n",
        "# Plot the data after oversampling\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled, cmap='viridis')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Data after oversampling')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Undersample the majority class using RandomUnderSampler\n",
        "undersampler = RandomUnderSampler(sampling_strategy={0: 3 * class_distribution_after[1]})\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "# Count the class distribution after undersampling\n",
        "class_distribution_after_undersampling = Counter(y_resampled)\n",
        "print(\"Class distribution after undersampling:\", class_distribution_after_undersampling)\n",
        "\n",
        "# Plot the data after undersampling\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled, cmap='viridis')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Data after undersampling')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RsyyDpHEIu_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Assign feature data to X and target data to y\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Print the dimensions of the training set and testing set\n",
        "print(\"Training set dimensions:\", X_train.shape)\n",
        "print(\"Testing set dimensions:\", X_test.shape)\n",
        "\n",
        "# Standardize the feature data in the training set\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same scaling transformation on the testing set\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Print the first 5 rows of the standardized training set\n",
        "print(pd.DataFrame(X_train_scaled, columns=iris.feature_names).head())\n"
      ],
      "metadata": {
        "id": "kLWhW4B2I7QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-NVg7RjyeTk"
      },
      "source": [
        "## Loading Public Notebooks Directly from GitHub\n",
        "\n",
        "Colab can load public github notebooks directly, with no required authorization step.\n",
        "\n",
        "For example, consider the notebook at this address: https://github.com/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb.\n",
        "\n",
        "The direct colab link to this notebook is: https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb.\n",
        "\n",
        "To generate such links in one click, you can use the [Open in Colab](https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo) Chrome extension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzIRIt9d2huC"
      },
      "source": [
        "## Browsing GitHub Repositories from Colab\n",
        "\n",
        "Colab also supports special URLs that link directly to a GitHub browser for any user/organization, repository, or branch. For example:\n",
        "\n",
        "- http://colab.research.google.com/github will give you a general github browser, where you can search for any github organization or username.\n",
        "- http://colab.research.google.com/github/googlecolab/ will open the repository browser for the ``googlecolab`` organization. Replace ``googlecolab`` with any other github org or user to see their repositories.\n",
        "- http://colab.research.google.com/github/googlecolab/colabtools/ will let you browse the main branch of the ``colabtools`` repository within the ``googlecolab`` organization. Substitute any user/org and repository to see its contents.\n",
        "- http://colab.research.google.com/github/googlecolab/colabtools/blob/master will let you browse ``master`` branch of the ``colabtools`` repository within the ``googlecolab`` organization. (don't forget the ``blob`` here!) You can specify any valid branch for any valid repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmai0dD30XzL"
      },
      "source": [
        "## Loading Private Notebooks\n",
        "\n",
        "Loading a notebook from a private GitHub repository is possible, but requires an additional step to allow Colab to access your files.\n",
        "Do the following:\n",
        "\n",
        "1. Navigate to http://colab.research.google.com/github.\n",
        "2. Click the \"Include Private Repos\" checkbox.\n",
        "3. In the popup window, sign-in to your Github account and authorize Colab to read the private files.\n",
        "4. Your private repositories and notebooks will now be available via the github navigation pane."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J3NBxtZpPcK"
      },
      "source": [
        "## Saving Notebooks To GitHub or Drive\n",
        "\n",
        "Any time you open a GitHub hosted notebook in Colab, it opens a new editable view of the notebook. You can run and modify the notebook without worrying about overwriting the source.\n",
        "\n",
        "If you would like to save your changes from within Colab, you can use the File menu to save the modified notebook either to Google Drive or back to GitHub. Choose **File→Save a copy in Drive** or **File→Save a copy to GitHub** and follow the resulting prompts. To save a Colab notebook to GitHub requires giving Colab permission to push the commit to your repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QAWNjizy_3O"
      },
      "source": [
        "## Open In Colab Badge\n",
        "\n",
        "Anybody can open a copy of any github-hosted notebook within Colab. To make it easier to give people access to live views of GitHub-hosted notebooks,\n",
        "colab provides a [shields.io](http://shields.io/)-style badge, which appears as follows:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "\n",
        "The markdown for the above badge is the following:\n",
        "\n",
        "```markdown\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "```\n",
        "\n",
        "The HTML equivalent is:\n",
        "\n",
        "```HTML\n",
        "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "```\n",
        "\n",
        "Remember to replace the notebook URL in this template with the notebook you want to link to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VQqVi-3ScBC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab-github-demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}